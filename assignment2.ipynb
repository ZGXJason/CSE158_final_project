{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE158 Assignment 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. DATA Pre-processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_json(\"renttherunway_final_data.json.gz\", \n",
    "                  orient=\"records\",\n",
    "                  lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_height_to_inches(x):\n",
    "    \"\"\"\n",
    "    Convert height to inches.\n",
    "    Returns NaN if parsing fails.\n",
    "    \"\"\"\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    x = str(x).strip()\n",
    "    m = re.match(r\"(\\d+)\\s*'\\s*(\\d+)?\", x)\n",
    "    if not m:\n",
    "        return np.nan\n",
    "    feet = int(m.group(1))\n",
    "    inches = int(m.group(2)) if m.group(2) is not None else 0\n",
    "    return feet * 12 + inches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/95/s7m5xrw107bfb2j1tyg3jdzc0000gn/T/ipykernel_31167/3279640882.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;31m# Cup -> numeric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bust_cup_num'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bust_cup'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcup_to_numeric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;31m# BMI + simple ratio weight/height\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'BMI'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_bmi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_lbs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'height_inches'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_per_inch'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_lbs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'height_inches'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'body type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'body type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unknown'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/95/s7m5xrw107bfb2j1tyg3jdzc0000gn/T/ipykernel_31167/3279640882.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(weight_lbs, height_inches)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_bmi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_lbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight_inches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \"\"\"\n\u001b[1;32m     53\u001b[0m     \u001b[0mBMI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m^\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \"\"\"\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_lbs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheight_inches\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mheight_inches\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mweight_kg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight_lbs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.453592\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mheight_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheight_inches\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.0254\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1575\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1577\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1578\u001b[0m             \u001b[0;34mf\"\u001b[0m\u001b[0;34mThe truth value of a \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m is ambiguous. \u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m         \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "def parse_weight_lbs(x):\n",
    "    \"\"\"\n",
    "    Extract numeric part from strings like '137lbs'.\n",
    "    \"\"\"\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    x = str(x)\n",
    "    m = re.search(r\"(\\d+\\.?\\d*)\", x)\n",
    "    if not m:\n",
    "        return np.nan\n",
    "    return float(m.group(1))\n",
    "\n",
    "\n",
    "def parse_bust_band_and_cup(x):\n",
    "    \"\"\"\n",
    "    Parse '34d' -> (34, 'D').\n",
    "    Returns (np.nan, np.nan) if parsing fails.\n",
    "    \"\"\"\n",
    "    if pd.isna(x):\n",
    "        return np.nan, np.nan\n",
    "    x = str(x).strip().upper()  # e.g. '34D'\n",
    "    m = re.match(r\"(\\d+)\\s*([A-Z]+)\", x)\n",
    "    if not m:\n",
    "        return np.nan, np.nan\n",
    "    band = float(m.group(1))\n",
    "    cup = m.group(2)  # e.g. D, DD\n",
    "    return band, cup\n",
    "\n",
    "def cup_to_numeric(cup):\n",
    "    \"\"\"\n",
    "    Map cup letters to an ordered numeric scale.\n",
    "    You can extend this mapping if your data has more.\n",
    "    \"\"\"\n",
    "    if pd.isna(cup):\n",
    "        return np.nan\n",
    "    cup = str(cup).upper()\n",
    "    cup_map = {\n",
    "        \"AA\": 0,\n",
    "        \"A\": 1,\n",
    "        \"B\": 2,\n",
    "        \"C\": 3,\n",
    "        \"D\": 4,\n",
    "        \"DD\": 5,\n",
    "        \"DDD\": 6,\n",
    "        \"E\": 7,\n",
    "        \"F\": 8\n",
    "    }\n",
    "    return cup_map.get(cup, np.nan)\n",
    "\n",
    "\n",
    "def compute_bmi(weight_lbs, height_inches):\n",
    "    \"\"\"\n",
    "    BMI = weight(kg) / height(m)^2.\n",
    "    \"\"\"\n",
    "    if pd.isna(weight_lbs) or pd.isna(height_inches) or height_inches == 0:\n",
    "        return np.nan\n",
    "    weight_kg = weight_lbs * 0.453592\n",
    "    height_m = height_inches * 0.0254\n",
    "    return weight_kg / (height_m ** 2)\n",
    "\n",
    "df = df[df['fit'].notna()].copy()\n",
    "\n",
    "# Standardize fit labels to lowercase\n",
    "df['fit'] = df['fit'].str.lower().str.strip()\n",
    "\n",
    "# Filter to the three classes we care about\n",
    "valid_fits = {'small', 'fit', 'large'}\n",
    "df = df[df['fit'].isin(valid_fits)].copy()\n",
    "\n",
    "# Encode target in two ways:\n",
    "# 1) class_encoding: small=0, fit=1, large=2 (for classification models)\n",
    "# 2) numeric_encoding: small=-1, fit=0, large=1 (for computing mean fit bias)\n",
    "fit_to_class = {'small': 0, 'fit': 1, 'large': 2}\n",
    "fit_to_num = {'small': -1, 'fit': 0, 'large': 1}\n",
    "\n",
    "df['fit_class'] = df['fit'].map(fit_to_class)\n",
    "df['fit_num'] = df['fit'].map(fit_to_num)\n",
    "\n",
    "df['height_inches'] = df['height'].apply(parse_height_to_inches)\n",
    "\n",
    "# Weight -> lbs (numeric)\n",
    "df['weight_lbs'] = df['weight'].apply(parse_weight_lbs)\n",
    "\n",
    "# Age -> numeric\n",
    "df['age'] = pd.to_numeric(df['age'], errors='coerce')\n",
    "\n",
    "# Bust size -> band + cup\n",
    "bust_band_list = []\n",
    "bust_cup_list = []\n",
    "\n",
    "for val in df['bust size']:\n",
    "    band, cup = parse_bust_band_and_cup(val)\n",
    "    bust_band_list.append(band)\n",
    "    bust_cup_list.append(cup)\n",
    "\n",
    "df['bust_band'] = bust_band_list\n",
    "df['bust_cup'] = bust_cup_list\n",
    "\n",
    "# Cup -> numeric\n",
    "df['bust_cup_num'] = df['bust_cup'].apply(cup_to_numeric)\n",
    "\n",
    "# BMI + simple ratio weight/height\n",
    "df['BMI'] = compute_bmi(df['weight_lbs'], df['height_inches'])\n",
    "df['weight_per_inch'] = df['weight_lbs'] / df['height_inches']\n",
    "\n",
    "df['body type'] = df['body type'].fillna('unknown')\n",
    "\n",
    "# Category: fill missing with 'unknown'\n",
    "df['category'] = df['category'].fillna('unknown')\n",
    "\n",
    "# One-hot encode category and body type\n",
    "df = pd.get_dummies(df,\n",
    "                    columns=['category', 'body type'],\n",
    "                    prefix=['cat', 'body'],\n",
    "                    dummy_na=False)\n",
    "\n",
    "# ======================================\n",
    "# 5. Item-level aggregate features\n",
    "# ======================================\n",
    "\n",
    "# For each item, compute stats of fit_num\n",
    "item_stats = df.groupby('item_id')['fit_num'].agg(\n",
    "    item_fit_mean='mean'\n",
    ").reset_index()\n",
    "\n",
    "# Also item-level probability of small / large\n",
    "item_small_rate = df.groupby('item_id')['fit'].apply(\n",
    "    lambda x: (x == 'small').mean()\n",
    ").reset_index(name='item_small_rate')\n",
    "\n",
    "item_large_rate = df.groupby('item_id')['fit'].apply(\n",
    "    lambda x: (x == 'large').mean()\n",
    ").reset_index(name='item_large_rate')\n",
    "\n",
    "# Merge item stats back\n",
    "df = df.merge(item_stats, on='item_id', how='left')\n",
    "df = df.merge(item_small_rate, on='item_id', how='left')\n",
    "df = df.merge(item_large_rate, on='item_id', how='left')\n",
    "\n",
    "\n",
    "# ======================================\n",
    "# 6. User-level aggregate features\n",
    "# ======================================\n",
    "\n",
    "# User mean fit bias: numeric encoding\n",
    "user_stats = df.groupby('user_id')['fit_num'].agg(\n",
    "    user_fit_mean='mean'\n",
    ").reset_index()\n",
    "\n",
    "df = df.merge(user_stats, on='user_id', how='left')\n",
    "# ======================================\n",
    "# 7. Simple target encoding of user_id / item_id\n",
    "#    (using fit_class for classification signal)\n",
    "# ======================================\n",
    "\n",
    "# user_id -> average class value\n",
    "user_te = df.groupby('user_id')['fit_class'].mean().reset_index()\n",
    "user_te = user_te.rename(columns={'fit_class': 'user_fit_class_mean'})\n",
    "df = df.merge(user_te, on='user_id', how='left')\n",
    "\n",
    "# item_id -> average class value\n",
    "item_te = df.groupby('item_id')['fit_class'].mean().reset_index()\n",
    "item_te = item_te.rename(columns={'fit_class': 'item_fit_class_mean'})\n",
    "df = df.merge(item_te, on='item_id', how='left')\n",
    "\n",
    "feature_cols = [\n",
    "    # user-level numeric\n",
    "    'height_inches',\n",
    "    'weight_lbs',\n",
    "    'age',\n",
    "    'bust_band',\n",
    "    'bust_cup_num',\n",
    "    'BMI',\n",
    "    'weight_per_inch',\n",
    "\n",
    "    # clothing size\n",
    "    'size',                 # selected size (numeric in your dataset)\n",
    "\n",
    "    # item-level aggregates\n",
    "    'item_fit_mean',\n",
    "    'item_small_rate',\n",
    "    'item_large_rate',\n",
    "\n",
    "    # user-level aggregates\n",
    "    'user_fit_mean',\n",
    "\n",
    "    # target encodings\n",
    "    'user_fit_class_mean',\n",
    "    'item_fit_class_mean',\n",
    "]\n",
    "\n",
    "one_hot_cols = [c for c in df.columns if c.startswith('cat_') or c.startswith('body_')]\n",
    "feature_cols.extend(one_hot_cols)\n",
    "\n",
    "# Drop rows with missing values in the selected features (simple approach)\n",
    "df_model = df.dropna(subset=feature_cols + ['fit_class']).copy()\n",
    "\n",
    "X = df_model[feature_cols]\n",
    "y = df_model['fit_class']\n",
    "\n",
    "print(\"Number of samples after preprocessing:\", len(df_model))\n",
    "print(\"Number of features:\", X.shape[1])\n",
    "\n",
    "\n",
    "# ======================================\n",
    "# 9. (Optional) Train/validation split by user_id\n",
    "# ======================================\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# To avoid leakage, split by user_id, not by random rows.\n",
    "users = df_model['user_id'].unique()\n",
    "train_users, test_users = train_test_split(users, test_size=0.2, random_state=42)\n",
    "\n",
    "train_mask = df_model['user_id'].isin(train_users)\n",
    "test_mask = df_model['user_id'].isin(test_users)\n",
    "\n",
    "X_train, y_train = X[train_mask], y[train_mask]\n",
    "X_test, y_test = X[test_mask], y[test_mask]\n",
    "\n",
    "print(\"Train samples:\", len(X_train))\n",
    "print(\"Test samples:\", len(X_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
