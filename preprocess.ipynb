{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651fed02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 0. Imports and data loading\n",
    "# ==============================\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"renttherunway_final_data.json.gz\", \n",
    "                  orient=\"records\",\n",
    "                  lines=True)\n",
    "\n",
    "# Example: load from CSV (change this to your file path)\n",
    "# df = pd.read_csv(\"rent_the_runway.csv\")\n",
    "\n",
    "# If you already have df in memory, you can skip the load line above.\n",
    "# For now, let's just assume df exists.\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 1. Helper functions for specific columns\n",
    "# ==========================================\n",
    "\n",
    "def parse_height_to_inches(x):\n",
    "    \"\"\"\n",
    "    Convert height like \"5' 8\\\"\" or \"5'8\\\"\" or \"5'8\" to inches.\n",
    "    Returns NaN if parsing fails.\n",
    "    \"\"\"\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    x = str(x).strip()\n",
    "    # Match feet and optional inches\n",
    "    m = re.match(r\"(\\d+)\\s*'\\s*(\\d+)?\", x)\n",
    "    if not m:\n",
    "        return np.nan\n",
    "    feet = int(m.group(1))\n",
    "    inches = int(m.group(2)) if m.group(2) is not None else 0\n",
    "    return feet * 12 + inches\n",
    "\n",
    "\n",
    "def parse_weight_lbs(x):\n",
    "    \"\"\"\n",
    "    Extract numeric part from strings like '137lbs'.\n",
    "    \"\"\"\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    x = str(x)\n",
    "    m = re.search(r\"(\\d+\\.?\\d*)\", x)\n",
    "    if not m:\n",
    "        return np.nan\n",
    "    return float(m.group(1))\n",
    "\n",
    "\n",
    "def parse_bust_band_and_cup(x):\n",
    "    \"\"\"\n",
    "    Parse '34d' -> (34, 'D').\n",
    "    Returns (np.nan, np.nan) if parsing fails.\n",
    "    \"\"\"\n",
    "    if pd.isna(x):\n",
    "        return np.nan, np.nan\n",
    "    x = str(x).strip().upper()  # e.g. '34D'\n",
    "    m = re.match(r\"(\\d+)\\s*([A-Z]+)\", x)\n",
    "    if not m:\n",
    "        return np.nan, np.nan\n",
    "    band = float(m.group(1))\n",
    "    cup = m.group(2)  # e.g. D, DD\n",
    "    return band, cup\n",
    "\n",
    "\n",
    "def cup_to_numeric(cup):\n",
    "    \"\"\"\n",
    "    Map cup letters to an ordered numeric scale.\n",
    "    You can extend this mapping if your data has more.\n",
    "    \"\"\"\n",
    "    if pd.isna(cup):\n",
    "        return np.nan\n",
    "    cup = str(cup).upper()\n",
    "    cup_map = {\n",
    "        \"AA\": 0,\n",
    "        \"A\": 1,\n",
    "        \"B\": 2,\n",
    "        \"C\": 3,\n",
    "        \"D\": 4,\n",
    "        \"DD\": 5,\n",
    "        \"DDD\": 6,\n",
    "        \"E\": 7,\n",
    "        \"F\": 8\n",
    "    }\n",
    "    return cup_map.get(cup, np.nan)\n",
    "\n",
    "\n",
    "def compute_bmi(weight_lbs, height_inches):\n",
    "    \"\"\"\n",
    "    BMI = weight(kg) / height(m)^2.\n",
    "    \"\"\"\n",
    "    if pd.isna(weight_lbs) or pd.isna(height_inches) or height_inches == 0:\n",
    "        return np.nan\n",
    "    weight_kg = weight_lbs * 0.453592\n",
    "    height_m = height_inches * 0.0254\n",
    "    return weight_kg / (height_m ** 2)\n",
    "\n",
    "\n",
    "# =============================================\n",
    "# 2. Basic cleaning + target label processing\n",
    "# =============================================\n",
    "\n",
    "# Keep only rows with non-null fit label\n",
    "df = df[df['fit'].notna()].copy()\n",
    "\n",
    "# Standardize fit labels to lowercase\n",
    "df['fit'] = df['fit'].str.lower().str.strip()\n",
    "\n",
    "# Filter to the three classes we care about\n",
    "valid_fits = {'small', 'fit', 'large'}\n",
    "df = df[df['fit'].isin(valid_fits)].copy()\n",
    "\n",
    "# Encode target in two ways:\n",
    "# 1) class_encoding: small=0, fit=1, large=2 (for classification models)\n",
    "# 2) numeric_encoding: small=-1, fit=0, large=1 (for computing mean fit bias)\n",
    "fit_to_class = {'small': 0, 'fit': 1, 'large': 2}\n",
    "fit_to_num = {'small': -1, 'fit': 0, 'large': 1}\n",
    "\n",
    "df['fit_class'] = df['fit'].map(fit_to_class)\n",
    "df['fit_num'] = df['fit'].map(fit_to_num)\n",
    "\n",
    "\n",
    "# ======================================\n",
    "# 3. Process user-level numeric fields\n",
    "# ======================================\n",
    "\n",
    "# Height -> inches\n",
    "df['height_inches'] = df['height'].apply(parse_height_to_inches)\n",
    "\n",
    "# Weight -> lbs (numeric)\n",
    "df['weight_lbs'] = df['weight'].apply(parse_weight_lbs)\n",
    "\n",
    "# Age -> numeric\n",
    "df['age'] = pd.to_numeric(df['age'], errors='coerce')\n",
    "\n",
    "# Bust size -> band + cup\n",
    "bust_band_list = []\n",
    "bust_cup_list = []\n",
    "\n",
    "for val in df['bust size']:\n",
    "    band, cup = parse_bust_band_and_cup(val)\n",
    "    bust_band_list.append(band)\n",
    "    bust_cup_list.append(cup)\n",
    "\n",
    "df['bust_band'] = bust_band_list\n",
    "df['bust_cup'] = bust_cup_list\n",
    "\n",
    "# Cup -> numeric\n",
    "df['bust_cup_num'] = df['bust_cup'].apply(cup_to_numeric)\n",
    "\n",
    "# BMI + simple ratio weight/height\n",
    "df['BMI'] = compute_bmi(df['weight_lbs'], df['height_inches'])\n",
    "df['weight_per_inch'] = df['weight_lbs'] / df['height_inches']\n",
    "\n",
    "\n",
    "# ======================================\n",
    "# 4. Process categorical features\n",
    "# ======================================\n",
    "\n",
    "# Body type: fill missing with 'unknown'\n",
    "df['body type'] = df['body type'].fillna('unknown')\n",
    "\n",
    "# Category: fill missing with 'unknown'\n",
    "df['category'] = df['category'].fillna('unknown')\n",
    "\n",
    "# One-hot encode category and body type\n",
    "df = pd.get_dummies(df,\n",
    "                    columns=['category', 'body type'],\n",
    "                    prefix=['cat', 'body'],\n",
    "                    dummy_na=False)\n",
    "\n",
    "\n",
    "# ======================================\n",
    "# 5. Item-level aggregate features\n",
    "# ======================================\n",
    "\n",
    "# For each item, compute stats of fit_num\n",
    "item_stats = df.groupby('item_id')['fit_num'].agg(\n",
    "    item_fit_mean='mean'\n",
    ").reset_index()\n",
    "\n",
    "# Also item-level probability of small / large\n",
    "item_small_rate = df.groupby('item_id')['fit'].apply(\n",
    "    lambda x: (x == 'small').mean()\n",
    ").reset_index(name='item_small_rate')\n",
    "\n",
    "item_large_rate = df.groupby('item_id')['fit'].apply(\n",
    "    lambda x: (x == 'large').mean()\n",
    ").reset_index(name='item_large_rate')\n",
    "\n",
    "# Merge item stats back\n",
    "df = df.merge(item_stats, on='item_id', how='left')\n",
    "df = df.merge(item_small_rate, on='item_id', how='left')\n",
    "df = df.merge(item_large_rate, on='item_id', how='left')\n",
    "\n",
    "\n",
    "# ======================================\n",
    "# 6. User-level aggregate features\n",
    "# ======================================\n",
    "\n",
    "# User mean fit bias: numeric encoding\n",
    "user_stats = df.groupby('user_id')['fit_num'].agg(\n",
    "    user_fit_mean='mean'\n",
    ").reset_index()\n",
    "\n",
    "df = df.merge(user_stats, on='user_id', how='left')\n",
    "\n",
    "\n",
    "# ======================================\n",
    "# 7. Simple target encoding of user_id / item_id\n",
    "#    (using fit_class for classification signal)\n",
    "# ======================================\n",
    "\n",
    "# user_id -> average class value\n",
    "user_te = df.groupby('user_id')['fit_class'].mean().reset_index()\n",
    "user_te = user_te.rename(columns={'fit_class': 'user_fit_class_mean'})\n",
    "df = df.merge(user_te, on='user_id', how='left')\n",
    "\n",
    "# item_id -> average class value\n",
    "item_te = df.groupby('item_id')['fit_class'].mean().reset_index()\n",
    "item_te = item_te.rename(columns={'fit_class': 'item_fit_class_mean'})\n",
    "df = df.merge(item_te, on='item_id', how='left')\n",
    "\n",
    "\n",
    "# ======================================\n",
    "# 8. Final feature selection\n",
    "# ======================================\n",
    "\n",
    "# Example: choose numeric + one-hot + encodings\n",
    "# (You can adjust this list based on experiments.)\n",
    "feature_cols = [\n",
    "    # user-level numeric\n",
    "    'height_inches',\n",
    "    'weight_lbs',\n",
    "    'age',\n",
    "    'bust_band',\n",
    "    'bust_cup_num',\n",
    "    'BMI',\n",
    "    'weight_per_inch',\n",
    "\n",
    "    # clothing size\n",
    "    'size',                 # selected size (numeric in your dataset)\n",
    "\n",
    "    # item-level aggregates\n",
    "    'item_fit_mean',\n",
    "    'item_small_rate',\n",
    "    'item_large_rate',\n",
    "\n",
    "    # user-level aggregates\n",
    "    'user_fit_mean',\n",
    "\n",
    "    # target encodings\n",
    "    'user_fit_class_mean',\n",
    "    'item_fit_class_mean',\n",
    "]\n",
    "\n",
    "# Add all one-hot columns (category & body type)\n",
    "one_hot_cols = [c for c in df.columns if c.startswith('cat_') or c.startswith('body_')]\n",
    "feature_cols.extend(one_hot_cols)\n",
    "\n",
    "# Drop rows with missing values in the selected features (simple approach)\n",
    "df_model = df.dropna(subset=feature_cols + ['fit_class']).copy()\n",
    "\n",
    "X = df_model[feature_cols]\n",
    "y = df_model['fit_class']\n",
    "\n",
    "print(\"Number of samples after preprocessing:\", len(df_model))\n",
    "print(\"Number of features:\", X.shape[1])\n",
    "\n",
    "\n",
    "# ======================================\n",
    "# 9. (Optional) Train/validation split by user_id\n",
    "# ======================================\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# To avoid leakage, split by user_id, not by random rows.\n",
    "users = df_model['user_id'].unique()\n",
    "train_users, test_users = train_test_split(users, test_size=0.2, random_state=42)\n",
    "\n",
    "train_mask = df_model['user_id'].isin(train_users)\n",
    "test_mask = df_model['user_id'].isin(test_users)\n",
    "\n",
    "X_train, y_train = X[train_mask], y[train_mask]\n",
    "X_test, y_test = X[test_mask], y[test_mask]\n",
    "\n",
    "print(\"Train samples:\", len(X_train))\n",
    "print(\"Test samples:\", len(X_test))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
